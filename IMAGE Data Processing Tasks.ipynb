{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTERING AND BLURRING to extract Best FEATURES from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing is used for NOISE FILTERING PURPOSE\n",
    "\n",
    "#Filter are used for EDGE DETECTION . They use DIFFERENT VALUES in the kernel inorder to FETCH DIFFERENT EDGES .\n",
    "#FOR DIAGONAL EDGE DETECTION , different valued kernal would be needed/used . For horizontal edge detection ,DIFFERENT valued Kernal would be needed . for VERTICAL EDGE DETECTION , VALUES in the Kernal would be Different \n",
    "\n",
    "#Filter are used for BLURING \n",
    "#Filter are used for NOISE REMOVING \n",
    "#Filter are used for ONLY BACKGROUD FOCUSED \n",
    "#Filter are SHARPENING particular Objects \n",
    "\n",
    "#1D SIGNALS and 1D IMAGES can be FILTERED using low pass filter  (USED for BLURING and REMOVING NOISES PURPOSES )\n",
    "#1D SIGNALS and 1D IMAGES can be FILTERED using HIGH pass filter (USED for FINDING EDGES in the IMAGES )\n",
    "\n",
    "\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = cv2.imread(r\"C:\\Users\\90536\\Desktop\\images\\lena.jpg\" )\n",
    "\n",
    "cvtImage = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Homogenous Filter : All pixels CONTRIBUTE equal weights . It is able to REDUCE NOISE and also did a little bluring of the image\n",
    "#( Homogenous Filter : USED for BLURING and REMOVING NOISES PURPOSES )\n",
    "\n",
    "KERNAL = np.ones((5,5) , np.float32)/25\n",
    "dst = cv2.filter2D( cvtImage , -1 , KERNAL )\n",
    "\n",
    "#AVERAGING Algorithm for Bluring \n",
    "BLUR = cv2.blur( cvtImage , (5 , 5 ))\n",
    "\n",
    "#Gausian Filter : It uses Different WEIGHTED KERNAL  in x Direction and also uses Different WEIGHTED KERNAL  in y Direction . \n",
    "#For an KERNAL WINDOW , Pixels located at SIDE has LOWER WEIGHT wrt PIXELS located at the CENTER \n",
    "GAUSSIANBLUR = cv2.GaussianBlur(cvtImage , (5,5) , 0)\n",
    "\n",
    "#Median Filter : It replaces Each Pixel Value by the MEDIAN OF THE NEIGHBOURING PIXELS .Good for SALT AND PEPPER NOISE (white dots and black dots ARE PRESENT on the IMAGE )\n",
    "Median = cv2.medianBlur( cvtImage , 5)# 5 is a KERNAL_SIZE\n",
    "\n",
    "#Bilatral Filter \n",
    "#To make EDGES SHARPER  . Edges became a little sharper wrt Other Filters  . It also REMOVES the Noise \n",
    "BilateralFilter = cv2.bilateralFilter(cvtImage , 9 , 75 ,75 )\n",
    "\n",
    "titles =[ ' cvtImage' , 'HomogenousFilterImage' , 'blur' , 'GAUSSIANBLUR' ,'MedainFilter' , 'BilateralFilter']\n",
    "\n",
    "images = [cvtImage ,dst  , BLUR , GAUSSIANBLUR , Median ,BilateralFilter]\n",
    "\n",
    "for i in range(6) :\n",
    "    plt.subplot( 2 , 3 , i+1 ) \n",
    "    plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    \n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORPHOLOGICAL TRANSFORMATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MORPHOLOGICAL TRANSFORMATION are OPERATIONS based on Image SHAPE . \n",
    "\n",
    "#MORPHOLOGICAL TRANSFORMATION are performed on BINARY IMAGES \n",
    "\n",
    "#Kernel is to CHANGE a PIXEL VALUE      by USING  NEARBY/NEIGHBOUR PIXELS\n",
    "\n",
    "\n",
    "\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = cv2.imread(r\"C:\\Users\\90536\\Desktop\\images\\smarties.png\" , 0)\n",
    "\n",
    "RET , MASK = cv2.threshold( image , 220 , 255 , cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernal = np.ones( (2, 2) , np.uint8)\n",
    "DILATION = cv2.dilate(MASK , kernal , iterations  = 1)    \n",
    "# The shape of the OBJECTS is CHANGED . They became BIGGER and BIGGER if iteration value is INCREASED or kernal shape is INCREASED i.e (5 ,5 ) will PRODUCE bigger objects wrt (3,3) or (2,2)\n",
    "EROSION  = cv2.erode( MASK , kernal ,iterations = 5 )   \n",
    "# The shape of the OBJECTS DONT CHANGE .ORIGINAL SHAPE of the Object is retained . \n",
    "# Kernal Goes through EACH and EVERY PIXELS of an IMAGE . \n",
    "#Kernal gives 1 only if ALL the PIXELS in that particular KERNAL WINDOW are ALL 1 . Else it will GEVERATE 0. Thus black dots in an OBJECT BECAME BIGGER . \n",
    "\n",
    "OpenMorphologyEx = cv2.morphologyEx( MASK , cv2.MORPH_OPEN , kernal ,iterations =1 )\n",
    "#It is erosion followed by dillation . It peforms quite well \n",
    "\n",
    "ClosingMorphologyEx = cv2.morphologyEx(MASK , cv2.MORPH_CLOSE , kernal , iterations =1)\n",
    "#It is dillation followed by errosion .\n",
    "\n",
    "GradientMorphologyEx = cv2.morphologyEx(MASK , cv2.MORPH_GRADIENT , kernal , iterations =1)\n",
    "#Difference b/w DILate and Erode   THUS WE GET EDGE of an OBJECT \n",
    "\n",
    "TopHatMorphologyEx = cv2.morphologyEx(MASK , cv2.MORPH_TOPHAT , kernal , iterations =1)\n",
    "#Difference b/w Mask and Opening of an mask\n",
    "\n",
    "\n",
    "titles = [ 'Image1' , 'MASK' , 'diluteeeeee' , 'EROSIONNNNNN' , 'OpenMorphologyEx' , 'ClosingMorphologyEx' , 'GradientMorphologyEx' , 'TopHatMorphologyEx']\n",
    "images = [ image  , MASK , DILATION , EROSION , OpenMorphologyEx ,ClosingMorphologyEx , GradientMorphologyEx ,  TopHatMorphologyEx]\n",
    "\n",
    "for i in range(8) :\n",
    "    plt.subplot( 3 , 3 , i+1 ) \n",
    "    plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARYING RESOLUTION (Gaussian and Laplacian Pyramid )\n",
    "## To reduce computational resources while processing images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can create IMAGES of Different RESOLUTION . \n",
    "#PYRAMAID: Where an IMAGE is subject to    RRREPEATED SSSSMOOTHING and SUBSAMPLING . inorder to SCALE them to VARIOUS \n",
    "#By pyramid function , you can DOWN SCALE the Image . First it will REDUCE the RESOULATION and scale to HALF . AND SECOND STEP it will REDUCE the RESOULATION and SCALE to 1/4th of the ORIGIONAL IMAGE. THEN 1/8 of the ORIGIONAL IMAGE and then ... 1/16th of the ORIGIONAL IMAGE \n",
    "\n",
    "#GAUSAIN pyramid : RRREPEATED filtering and SUBSAMPLING ofan IMAGE . There are TWO functions pyrUp and pyrDown \n",
    "\n",
    "#from IPython import get_ipython\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "#get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread(r\"C:\\Users\\90536\\Desktop\\images\\messi5.jpg\" , 0 )\n",
    "\n",
    "#Inorder to Copy an Image \n",
    "copyImage = image.copy()\n",
    "\n",
    "pyrDownImage = [copyImage]\n",
    "for i in range(6): #If we want to USE pyrDown 5 times OR we want to Reduce the RESOLUATION 5 times then use range(6)\n",
    "    pyrDownImage1=cv2.pyrDown(copyImage)\n",
    "    pyrDownImage.append(pyrDownImage1)\n",
    "    copyImage = pyrDownImage1.copy()\n",
    "    #cv2.imshow(str(i) , pyrDownImage1)\n",
    "    \n",
    "lastImage = pyrDownImage[5]\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(5 , 0 ,-1 ):\n",
    "    Gaussian_Extended=cv2.pyrUp(pyrDownImage[i])\n",
    "    Laplacian=cv2.subtract(pyrDownImage[i-1] , Gaussian_Extended)\n",
    "    cv2.imshow(str(i) ,Laplacian )\n",
    "    \n",
    "#cvtImage =cv2.cvtColor( image , cv2.COLOR_BGR2RGB)\n",
    "\n",
    "pyrDownImageOnce = cv2.pyrDown(image)              # 1/4th of the origional Image \n",
    "pyrDownImageTwice = cv2.pyrDown(pyrDownImageOnce)   # 1/8th of the origional Image\n",
    "\n",
    "#As you DECREASE the RESOLUTION of the Image by using pyrDown then INFORMATION(Color INFORMATION ) is LOST .\n",
    "#Thus if we try to perform pyrUp on pyrDownImageTwice then IT WILL NOT BE SAME pyrDownImageOnce (Only will be same SIZE but will be BLURRED as it has lost the INFORMATION )\n",
    "\n",
    "pyrUp = cv2.pyrUp(pyrDownImageTwice)\n",
    "\n",
    "#cv2.imshow('pyrDownImageOnce' , pyrDownImageOnce)\n",
    "\n",
    "#cv2.imshow('pyrDownImageTwice' , pyrDownImageTwice)\n",
    "\n",
    "#cv2.imshow('pyrUp_Of_pyrDownImageTwice' , pyrUp)\n",
    "cv2.imshow('image' , image)\n",
    "\n",
    "if cv2.waitKey(0)== 27:\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackbar (For User to CHANGE VALUES at run time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x): # x is a POSITION of the Trackbar\n",
    "    print(x)\n",
    "\n",
    "cv2.namedWindow('imageWindow')\n",
    "\n",
    "image= np.zeros((300 , 512 ,3) , np.uint8)\n",
    "cv2.createTrackbar('BLUE  ' ,  'imageWindow' , 0 , 255 ,nothing ) #Last value INDICATE THE FUNCTION which Executes if TRACKBAR Value CHANGES then \n",
    "cv2.createTrackbar('GREEN ' ,  'imageWindow' , 0 , 255 ,nothing )\n",
    "cv2.createTrackbar('RED ' ,  'imageWindow' , 0 , 255 ,nothing )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('imageWindow' , image)\n",
    "    r = cv2.getTrackbarPos('RED','imageWindow')\n",
    "    g = cv2.getTrackbarPos('GREEN','imageWindow')\n",
    "    b = cv2.getTrackbarPos('BLUE','imageWindow')\n",
    "    \n",
    "    #b = cv2.getTrackbarPos('TrackbarName1BLUE' , 'image1Window')\n",
    "    #g = cv2.getTrackbarPos('TrackbarName2GREEN' , 'image1Window') \n",
    "    #r = cv2.getTrackbarPos('TrackbarName3' , 'image1Window')\n",
    "    image[:] = [b,g,r]\n",
    "    \n",
    "    k= cv2.waitKey(1)\n",
    "    if k == 27:    \n",
    "        break\n",
    "    \n",
    "    \n",
    "    print(b )\n",
    "    print(' , ')\n",
    "    print(g)\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOUGH TRANSFORM to detect Lines and shape in Image \n",
    "# Without builtin function of Hough Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_line(img, angle_step=1, lines_are_white=True, value_threshold=5):\n",
    "    \n",
    "    thetas = np.deg2rad(np.arange(-90.0, 90.0, angle_step))\n",
    "    width, height = img.shape\n",
    "    diag_len = int(round(math.sqrt(width * width + height * height)))\n",
    "    rhos = np.linspace(-diag_len, diag_len, diag_len * 2)\n",
    "    \n",
    "    cos_t = np.cos(thetas)\n",
    "    sin_t = np.sin(thetas)\n",
    "    num_thetas = len(thetas)\n",
    "    \n",
    "    #Created hough space\n",
    "    accumulator = np.zeros((2 * diag_len, num_thetas), dtype=np.uint8)\n",
    "    \n",
    "    are_edges = img > value_threshold if lines_are_white else img < value_threshold\n",
    "    y_idxs, x_idxs = np.nonzero(are_edges)\n",
    "    \n",
    "    for i in range(len(x_idxs)):\n",
    "        x = x_idxs[i]\n",
    "        y = y_idxs[i]\n",
    "# To find the votes for each angle and rho value in hough space\n",
    "        for t_idx in range(num_thetas):\n",
    "            \n",
    "            rho = diag_len + int(round(x * cos_t[t_idx] + y * sin_t[t_idx]))\n",
    "            accumulator[rho, t_idx] += 1\n",
    "\n",
    "    return accumulator, thetas, rho \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hough_line(img, accumulator, thetas, rhos ):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax =plt.subplots(1, 2, figsize=(100, 100))\n",
    "    ax[0].imshow(img, cmap=plt.cm.gray)\n",
    "    ax[0].set_title('Input image')\n",
    "    ax[0].axis('image')\n",
    "\n",
    "    ax[1].imshow(accumulator, cmap='jet')\n",
    "    ax[1].set_aspect('auto', adjustable='box')\n",
    "    ax[1].set_title('Hough transform')\n",
    "    ax[1].set_xlabel('Angles ')\n",
    "    ax[1].set_ylabel('rho')\n",
    "    ax[1].axis('image')\n",
    "    lines = cv2.HoughLinesP(img,1,np.pi/180,100,minLineLength=20,maxLineGap=15)\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        cv2.line(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    cv2.imshow(\"image\" , image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "image = cv2.imread(\"C:\\im02.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur_image = cv2.GaussianBlur(gray_image, (3, 3), 1)\n",
    "edge_image = cv2.Canny(blur_image, 100, 200)\n",
    "img = edge_image\n",
    "\n",
    "accumulator, thetas, rhos = hough_line(img)\n",
    "show_hough_line(img, accumulator,thetas, rhos )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETECTING EDGES of an Image\n",
    "# without buitin Canny EDGE DETECTION Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "\n",
    "image = cv2.imread(\"C:\\im03.png\")\n",
    "height = int(image.shape[0])\n",
    "width = int(image.shape[1])\n",
    "\n",
    "gray_image = cv2.cvtColor(image ,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "Smoothed_image = cv2.GaussianBlur(gray_image , (5,5) , 1)\n",
    "\n",
    "\n",
    "def edge_detection(image):\n",
    "    \n",
    "    kernelX = np.array([[-1 , 0 , 1 ] , [-2 , 0 , 2 ] , [-1 , 0 , 1]], np.float32 )\n",
    "\n",
    "    kernalY = np.array([[ 1 , 2 , 1 ] , [ 0 , 0 , 0 ] , [-1 ,-2 ,-1]], np.float32 )\n",
    " \n",
    "    Gx = convolve2d(Smoothed_image , kernelX)\n",
    "    Gy = convolve2d(Smoothed_image , kernalY)\n",
    "    G= np.hypot(Gx , Gy)\n",
    "\n",
    "\n",
    "    #Normalized Magnitude\n",
    "    Magnitude = G / G.max() \n",
    "\n",
    "    Angle = np.arctan2(Gx , Gy)\n",
    "    \n",
    "    return (Magnitude , Angle  )\n",
    "\n",
    "Mag , Angle  = edge_detection(Smoothed_image)\n",
    "\n",
    "\n",
    "Mag = np.array(Mag)\n",
    "\n",
    "\n",
    "cv2.imshow(\"canny_edge_detection_image\" , Mag)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open and Capture Video from PC and apply thresholding to detect desirable features or Part of an Object in the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "    \n",
    "videoCapture=cv2.VideoCapture(0)    \n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar('LH' , 'Tracking' , 0 , 255 , nothing)\n",
    "\n",
    "cv2.createTrackbar(\"UH\" , 'Tracking' , 255 , 255 , nothing)\n",
    "\n",
    "cv2.createTrackbar(\"LS\" , 'Tracking' , 0 , 255 , nothing)\n",
    "cv2.createTrackbar(\"US\" , 'Tracking' , 255 , 255 , nothing)\n",
    "cv2.createTrackbar(\"LV\" , 'Tracking' , 0 , 255 , nothing)\n",
    "cv2.createTrackbar(\"UV\" , 'Tracking' , 255 , 255 , nothing)\n",
    "\n",
    "\n",
    "\n",
    "while(True):\n",
    "    #image=cv2.imread(r'C:\\Users\\90536\\Desktop\\images\\smarties.png')\n",
    "    \n",
    "    ret , image = videoCapture.read()\n",
    "    \n",
    "    LH=cv2.getTrackbarPos('LH' , 'Tracking')\n",
    "    UH=cv2.getTrackbarPos('UH' , 'Tracking')\n",
    "    LS=cv2.getTrackbarPos('LS' , 'Tracking')\n",
    "    US=cv2.getTrackbarPos('US' , 'Tracking')\n",
    "    LV=cv2.getTrackbarPos('LV' , 'Tracking')\n",
    "    UV=cv2.getTrackbarPos('UV' , 'Tracking')\n",
    "    \n",
    "    conv_image = cv2.cvtColor(image , cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    print(LH)\n",
    "    print(UH)\n",
    "    print(LS)\n",
    "    print(US)\n",
    "    print(LV)\n",
    "    print(UV)\n",
    "    \n",
    "    Lower_Thresold_ArrayValue_Blue_Color = np.array([LH , LS , LV])\n",
    "    Upper_Thresold_ArrayValue_Blue_Color = np.array([UH , US , UV])\n",
    "    \n",
    "    mask= cv2.inRange (conv_image , Lower_Thresold_ArrayValue_Blue_Color , Upper_Thresold_ArrayValue_Blue_Color )    # Inorder to FETCH ONLY Blue values OF an Image .\n",
    "    \n",
    "    res = cv2.bitwise_and(image , image , mask = mask)\n",
    "    \n",
    "    cv2.imshow('frame' , image)\n",
    "    cv2.imshow('mask' , mask)\n",
    "    cv2.imshow('resultant', res)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xff\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "        \n",
    "videoCapture.release()        \n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [ x for x in dir(cv2) if 'EVENT' in x]\n",
    "print(events)\n",
    "\n",
    "\n",
    "def newFunction ( event , x, y, flags , parameter):\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        blue = image[ y , x , 0]\n",
    "        green = image[ y , x , 1]\n",
    "        red = image[y , x , 2]\n",
    "        print( x , '   ,   ' , y)\n",
    "        text = str(blue) + ' , ' + str(green) + ' , ' + str(red)\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        cv2.putText(image , text , (x,y) , font , 0.8 , (255 , 255 ,50) , 1 , cv2.LINE_AA)\n",
    "        cv2.imshow('Window' , image)\n",
    "\n",
    "image = cv2.imread('lena.jpg')  \n",
    "cv2.imshow('Window' , image)\n",
    "\n",
    "cv2.setMouseCallback( 'Window' , newFunction )\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THRESHOLDING AND ADAPTIVE THRESHOLDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In THRESHOLDING technique , we have ONE THRESHOLD VALUE  which applies to ALL PIXELS in the image \n",
    "#In ADAPTIVE THRESHOLDING Technique , we have MANY THRESHOLD VALUE . for different REGIONS/SEGMENTS of an IMAGE \n",
    "\n",
    "\n",
    "#Inorder to OPEN THE MATPLOTLIB OUTPUT in the NEW WINDOW we will use these codes ELSE it's OUTPUT will not be OUTPUTED HERE.\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Thresholding is a Technique of SEPERATING an OBJECT from its BACKGROUND\n",
    "#It divides the INPUT Pixels INTO 2 Groups . 1st Group has PIXELS having VALUE LESSSER than the threshold value and  \n",
    "#2nd GROUP pIXELS will have VALUE GREATER than threshold value .\n",
    "\n",
    "\n",
    "image = cv2.imread(r\"C:\\Users\\90536\\Desktop\\images\\sudoku.png\" , 0)\n",
    "\n",
    "ret , thresholded_image1 = cv2.threshold(image , 127 , 255 , cv2.THRESH_BINARY)# cv2.THRESH_BINARY is one of MANYYY Types of THRESHOLDING TECHNIQUES\n",
    "ret , thresholded_image2 = cv2.threshold(image , 200 , 255 , cv2.THRESH_BINARY_INV)\n",
    "#If the Color Pixel is Greater than THRESHOLD value(in this case is 200) then \n",
    "# In cv2.THRESH_BINARY OR cv2.THRESH_BINARY_INV , in BINARY only 2 SEGMENTS of PIXELS are made AFTER THRESHOLDING TECHNIQUE , \n",
    "#In cv2.THRESH_BINARY , The PIXELS having value GREATER than 200 will be assigned 100 pixel value (in THIS CASE ONLY as 100 value is assigned ) AND  0 value is assigned to PIXELS with pixel value LESSER than 200\n",
    "#In cv2.THRESH_BINARY_ , The PIXELS having value LESSER than 200 will be assigned 100 pixel value (in THIS CASE ONLY as 100 value is assigned) AND  0 value is assigned to PIXELS with pixel value GREATER than 200\n",
    "\n",
    "\n",
    "ret , thresholded_image3 = cv2.threshold(image , 175 , 255 , cv2.THRESH_TRUNC)\n",
    "#if THRESOLDVALUE is 175 then LOWER than 175 pixels WILL REMAIN SAME(SAME as the ORIGINAL pixels ) AS BEFORE .There PIXEL value will not CHANGE at all\n",
    "#and PIXELS having value GREATER than 175 pixel     WILL ALL converted to 175 pixel value. #the second value 255 has not much role HERE . \n",
    "\n",
    "\n",
    "ret , thresholded_image4 = cv2.threshold(image , 175 , 255 , cv2.THRESH_TOZERO)\n",
    "\n",
    "\n",
    "#ADAPTIVE THRESOLDING : Different Thresolding Value for DIFFERENT REGION of the IMAGE \n",
    "#IT Calculates thresold value for SMALLER REGIONS and thus we have MULTIPLE THRESOLDVALUE for an IMAGE .\n",
    "# THRESOLDING basically WORKS on ILLUMINATION LEVEL . Higher Brightness region are SHOWN whereas LOWER BRIGHTNESS region BECAME EITHER BLACK when applied Thresholding\n",
    "\n",
    "ADTH1=cv2.adaptiveThreshold(image , 255 , cv2.ADAPTIVE_THRESH_MEAN_C , cv2.THRESH_BINARY , 11 , 2  ) # cv.ADAPTIVE_THRESH_MEAN_C is the ( MEAN of the Neighbourhood BLOCKSIZE/AREA )\n",
    "# It gives the MEAN of the  BLOCKSIZE * BLOCKSIZE  neighbourhood    MINUS C\n",
    "#Adavptive METHOD will decide HOW THRESHOLDING value is calculated\n",
    "\n",
    "#11 IS BLOCKSIZE\n",
    "#2 IS C\n",
    "\n",
    "\n",
    "ADTH2=cv2.adaptiveThreshold(image , 255 , cv2.ADAPTIVE_THRESH_GAUSSIAN_C  , cv2.THRESH_BINARY , 11 ,2 )\n",
    "#It gives the WEIGHTED SUM  of the  BLOCKSIZE * BLOCKSIZE  neighbourhood      MINUS C\n",
    "\n",
    "cv2.imshow('THRESH_BINARYWindow1' ,thresholded_image1 )\n",
    "cv2.imshow('THRESH_BINARY_INVWindow2' ,thresholded_image2 )\n",
    "cv2.imshow('THRESH_TRUNCWindow3' , thresholded_image3 )\n",
    "\n",
    "cv2.imshow('THRESH_TOZEROWindow4' , thresholded_image4 )\n",
    "\n",
    "cv2.imshow('ADAPTIVE_THRESH_MEAN_CWindow5' , ADTH1)\n",
    "\n",
    "cv2.imshow('ADAPTIVE_THRESH_GAUSSIAN_CWindow6' , ADTH2)\n",
    "\n",
    "\n",
    "cv2.imshow('ImageWindow' , image)\n",
    "\n",
    "if cv2.waitKey(0) == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAPLACE and SobelX  AND SobelY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Gradient: DIRECTIONAL CHANGE in the (INTENSITY or THE COLOR ) in the Image \n",
    "#Laplacian Gradient was able to FIND EDGES of the Objects \n",
    "\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "\n",
    "image = cv2.imread(r\"C:\\Users\\90536\\Desktop\\images\\sudoku.png\" , 0 )\n",
    "\n",
    "#cvtImage =cv2.cvtColor( image , cv2.COLOR_BGR2RGB)\n",
    "\n",
    "laplacian1 = cv2.Laplacian( image , cv2.CV_64F , ksize = 1) # We used cv2.CV_64F datatype as it Supports NEGATIVE VALUES TOO\n",
    "\n",
    "#Now we will take Absolute Value of the LAPLACIAN TRANSFORMATION and CONVERT to UNSIGNED 8 bit integer \n",
    "laplacianAbsolute_KERNALSIZE1 = np.uint8(np.absolute(laplacian1))\n",
    "\n",
    "laplacian2 = cv2.Laplacian( image , cv2.CV_64F , ksize = 5) # We used cv2.CV_64F datatype as it Supports NEGATIVE VALUES TOO\n",
    "\n",
    "#Now we will take Absolute Value of the LAPLACIAN TRANSFORMATION and CONVERT to UNSIGNED 8 bit integer \n",
    "laplacianAbsolute_KERNALSIZE5 = np.uint8(np.absolute(laplacian2))\n",
    "\n",
    "#Sobel \n",
    "\n",
    "sobelX =cv2.Sobel(image , cv2.CV_64F , 1  , 0 )# To tell the computer we want to use SobelX method we use 1 FOR dx \n",
    "#dx,direction accross x dimension .  Value is 1 IN THE ABOVE CASE\n",
    "#dx,direction accross Y dimension .  Value is 0 IN THE ABOVE CASE\n",
    "\n",
    "SobelY = cv2.Sobel(image , cv2.CV_64F , 0 , 1 )# To tell the computer we want to use SobelY method we use 1 FOR dy\n",
    "\n",
    "#YOU CAN ALSO GIVE THE KERNALSIZE VALUE for Sobal as shown in Laplasian method  \n",
    "\n",
    "\n",
    "#Now we will take Absolute Value of the LAPLACIAN TRANSFORMATION and CONVERT to UNSIGNED 8 bit integer \n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "\n",
    "sobelY  = np.uint8(np.absolute(SobelY))\n",
    "\n",
    "#YOU can also COMBINE the Results of sobelX and sobelY results to GET BOTH EDGES ALONG X and ALSO ALONG Y AXIS .\n",
    "SOBEL_COMBINE_VIA_BITWISE_OR = cv2.bitwise_or(sobelX ,sobelY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
